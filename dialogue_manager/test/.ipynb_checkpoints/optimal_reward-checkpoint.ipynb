{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rs': 0.75, 'rf': -0.41000000000000003, 'ra': 0, 'rb': -0.08, 'rc': -0.13}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal policy apparently\n",
    "# reward_function = {'rs': 0.30, 'rf': -0.8, 'ra': -0.64, 'rb': -0.9400000000000001, 'rc': -0.7}\n",
    "# {'rs': 0.47000000000000003, 'rf': -0.79, 'ra': -0.3, 'rb': -0.36, 'rc': -0.42}\n",
    "# 'rs': 0.76, 'rf': -0.5700000000000001, 'ra': -0.11, 'rb': -0.15000000000000002, 'rc': -0.19\n",
    "# reward_function = {'rs': 0.8, 'rf': -0.46, 'ra': -0.17, 'rb': -0.67, 'rc': -0.06999999999999999}\n",
    "# reward_function = {'rs': 0, 'rf': -0.03, 'ra': -0.28, 'rb': -0.58, 'rc': -0.95}\n",
    "# reward_function = {'rs': 0.75, 'rf': -0.41000000000000003, 'ra': 0, 'rb': -0.08, 'rc': -0.13}\n",
    "reward_function = {'rs': 0.92, 'rf': -1.0, 'ra': -0.04, 'rb': -0.17, 'rc': -0.25}\n",
    "reward_function\n",
    "# reward_function = {'rs' : 0.95,\n",
    "#                     'rf' : -0.95,\n",
    "#                     'ra' : -0.76,\n",
    "#                     'rb' : -0.76,\n",
    "#                     'rc' : -0.76}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = [[0.45423137, 0, 0.], \\\n",
    "                [0, 0.44068592, 0], \\\n",
    "                [0., 0., 0.44372564], \\\n",
    "                [0, 0, 0],\\\n",
    "                [0.27273065, 0.094109,   0.0675645 ]]\n",
    "avg_lens = [1.002800, 0.829600, 0.797600, 0, 0.904400]\n",
    "avg_successes = [0.859200, 0.912000, 0.938000, 0.836, 0.891600]\n",
    "\n",
    "# distributions = [[0.368, 0., 0.], \\\n",
    "#                 [0., 0.426, 0.], \\\n",
    "#                 [0., 0., 0.416], \\\n",
    "#                 [0.218, 0.110, 0.0487], ]\n",
    "# avg_lens = [3.16, 3.46, 3.40, 3.2]\n",
    "# avg_successes = [0.963, 0.953, 0.949, 0.951]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Rewards: [('Policy \"A?\"', 0.586672), ('Policy \"A or B?\"', 0.5815520000000001), ('Policy \"A or B or C?\"', 0.574392), ('All_Select', 0.55976), ('Mixed Policy', 0.590295302888796)]\n",
      "Reward Function: {'rs': 0.75, 'rf': -0.41000000000000003, 'ra': 0, 'rb': -0.08, 'rc': -0.13}\n"
     ]
    }
   ],
   "source": [
    "def calculate_reward_function(reward_function):\n",
    "    reward_names = ['ra', 'rb', 'rc', 'rs']\n",
    "    policy_names = ['Policy \"A?\"', 'Policy \"A or B?\"', 'Policy \"A or B or C?\"', 'All_Select', 'Mixed Policy']\n",
    "    policy_rewards = []\n",
    "    for i in range(len(distributions)):\n",
    "        if sum(distributions[i]) > 0:\n",
    "            cur_distribution = np.array(distributions[i])/sum(distributions[i])\n",
    "        cur_avg_len = avg_lens[i]\n",
    "        \n",
    "        listener_reward = 0.0\n",
    "        for j in range(len(cur_distribution)):\n",
    "            listener_reward += ( cur_avg_len * cur_distribution[j] * reward_function[reward_names[j]] )\n",
    "        listener_reward += ((avg_successes[i] * reward_function['rs']) + \\\n",
    "                            ((1 - avg_successes[i]) * reward_function['rf']))\n",
    "        total_reward = listener_reward\n",
    "        \n",
    "        policy_rewards.append(total_reward)\n",
    "    return list(zip(policy_names, policy_rewards))\n",
    "print('Policy Rewards:', calculate_reward_function(reward_function))\n",
    "print('Reward Function:', reward_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010677698081843712 691\n",
      "Reward Function: {'rs': 0.92, 'rf': -1.0, 'ra': -0.04, 'rb': -0.17, 'rc': -0.25}\n",
      "Policy Rewards: [('Policy \"A?\"', 0.609552), ('Policy \"A or B?\"', 0.6100080000000001), ('Policy \"A or B or C?\"', 0.6015599999999999), ('All_Select', 0.60512), ('Mixed Policy', 0.6206856980818438)]\n"
     ]
    }
   ],
   "source": [
    "working_rewards = []\n",
    "noincrement_counter = 0\n",
    "terminate_counter = 100000\n",
    "max_policies = 5000\n",
    "used = set()\n",
    "done= False\n",
    "possible_rewards = [0] + [-1*(0.01 + (i/100)) for i in range(100)]\n",
    "success_rewards = [0] + [(0.01 + (i/100)) for i in range(100)]\n",
    "# for ra in possible_rewards:\n",
    "#     for rb in possible_rewards:\n",
    "#         for rc in possible_rewards:\n",
    "#             for rspeaker in possible_rewards:\n",
    "while not done:\n",
    "#                 clarification_rewards = [ra, rb, rc]\n",
    "    clarification_rewards = []\n",
    "    for i in range(5):\n",
    "        clarification_rewards.append(random.choice(possible_rewards))\n",
    "#                 if tuple(clarification_rewards) in used:\n",
    "#                     continue\n",
    "#                 used.add(tuple(clarification_rewards))\n",
    "\n",
    "    reward_function['ra'] = clarification_rewards[0]\n",
    "    reward_function['rb'] = clarification_rewards[1]\n",
    "    reward_function['rc'] = clarification_rewards[2]\n",
    "#                 reward_function['rspeaker'] = clarification_rewards[3]\n",
    "    reward_function['rs'] = random.choice(success_rewards)\n",
    "    reward_function['rf'] = clarification_rewards[4]\n",
    "\n",
    "    policy_rewards = calculate_reward_function(reward_function)\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for pname, reward in policy_rewards[:-1]:\n",
    "        min_distance = min(min_distance, policy_rewards[-1][1] - reward)\n",
    "\n",
    "    if min_distance <= 0 or policy_rewards[-1][1] <= 0:\n",
    "        noincrement_counter += 1\n",
    "    else:\n",
    "        new_reward_function = dict()\n",
    "        for k in reward_function:\n",
    "            new_reward_function[k] = reward_function[k]\n",
    "#         print(reward_function)\n",
    "#         print(new_reward_function)\n",
    "#         print(policy_rewards)\n",
    "#         print(calculate_reward_function(new_reward_function))\n",
    "#         print('-------------------------')\n",
    "        working_rewards.append((policy_rewards, min_distance, new_reward_function))\n",
    "        noincrement_counter = 0\n",
    "\n",
    "    if len(working_rewards) > max_policies or noincrement_counter > terminate_counter:\n",
    "        done = True\n",
    "            # working_rewards\n",
    "all_differences = ([working_rewards[i][1] for i in range(len(working_rewards))])\n",
    "try:\n",
    "    max_difference, argmax_difference = (max(all_differences), np.argmax(all_differences))\n",
    "except Exception as e:\n",
    "    print('Terminate Counter: %d' % (terminate_counter,))\n",
    "else:\n",
    "    policy_rewards, _, reward_function = working_rewards[argmax_difference]\n",
    "    print(max_difference, len(working_rewards))\n",
    "    print('Reward Function:', reward_function)\n",
    "    print('Policy Rewards:', calculate_reward_function(reward_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01200736792920365"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance = max([working_rewards[i][1] for i in range(len(working_rewards))])\n",
    "max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9, -0.95, -0.15)\n",
      "0.4250000000000001 0.27599999999999997 0.417\n",
      "0.14900000000000013 0.008000000000000118\n"
     ]
    }
   ],
   "source": [
    "# vals = max_args(ravgp, ravgc, ravgs)\n",
    "vals = (0.9, -0.95, -0.15)\n",
    "print(vals)\n",
    "print(ravgp(*vals), ravgc(*vals), ravgs(*vals))\n",
    "print(ravgp(*vals) - ravgc(*vals), ravgp(*vals) - ravgs(*vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
