{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/sos/Dialogue_Research/color_in_context/system/dialogue_manager')\n",
    "from dataset.cic import make_or_load_cic\n",
    "import string\n",
    "import numpy as np\n",
    "import dataset\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cic = make_or_load_cic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8918"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cic._df[(cic._df['split'] == 'train') & (cic._df['lux_difficulty_rating'].sin([0,1,2,3]))].groupby('condition').count()\n",
    "# cic._df[cic._df['split'] == 'dev'].iloc[:2500].groupby('condition').count()\n",
    "\n",
    "y = cic._df[cic._df['condition'] == 'close'].sample().index\n",
    "y[0]\n",
    "# x = [0 for i in range(y + 1)]\n",
    "# x[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = cic._color_vocab\n",
    "\n",
    "tokens = set()\n",
    "for i in range(len(vocabulary)):\n",
    "    color_term = vocabulary.lookup_index(i)\n",
    "    for token in color_term.split():\n",
    "        for term in token.split('-'):\n",
    "            tokens.add(term)\n",
    "            \n",
    "def expansion(word):\n",
    "    result = set()\n",
    "    #deletions\n",
    "    #assuming mistake in upto one missing characters\n",
    "    deletions = set()\n",
    "    for i in range(len(word)):\n",
    "        new_word = word[:i] + word[i+1:]\n",
    "        deletions.add(new_word)\n",
    "    #additions\n",
    "    for letter in string.ascii_lowercase:\n",
    "        for i in range(len(word) + 1):\n",
    "            new_word = word[:i] + letter + word[i:]\n",
    "            result.add(new_word)\n",
    "    #deletion addition\n",
    "    for letter in string.ascii_lowercase:\n",
    "        for word in deletions:\n",
    "            for i in range(len(word) + 1):\n",
    "                new_word = word[:i] + letter + word[i:]\n",
    "                result.add(new_word)\n",
    "    \n",
    "    \n",
    "    return result | deletions\n",
    "\n",
    "cic._df.iloc[[cic[0]['row_index']]]\n",
    "token_counts = dict()\n",
    "for item in cic:\n",
    "    color_term = cic._df.iloc[item['row_index']]['lux_label']\n",
    "    for token in color_term.split():\n",
    "        for term in token.split('-'):\n",
    "            token_counts.setdefault(term, 0)\n",
    "            token_counts[term] += 1\n",
    "\n",
    "# expansion('blue')\n",
    "def expansion_to_correct_map(tokens, token_counts):\n",
    "    expansions = dict()\n",
    "    for term in tokens:\n",
    "        modifications = expansion(term)\n",
    "        for modified in modifications:\n",
    "            expansions.setdefault(modified, set())\n",
    "            try:\n",
    "                expansions[modified].add((term, token_counts[term]))\n",
    "            except Exception as e:\n",
    "                expansions[modified].add((term, 0))\n",
    "    return expansions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_correct_map = expansion_to_correct_map(tokens, token_counts)\n",
    "pickle.dump(exp_correct_map, open(os.path.dirname(dataset.__file__) + '/spellcheck_map', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue\n",
      "brown\n",
      "reddish\n",
      "yellow\n",
      "yellow\n",
      "blue\n"
     ]
    }
   ],
   "source": [
    "def get_correct_word(word, exp_correct_map):\n",
    "    possible_set = list(exp_correct_map[word])\n",
    "    if word in [term[0] for term in possible_set]:\n",
    "        return word\n",
    "    else:\n",
    "        ix = np.argmax([term[1] for term in possible_set])\n",
    "        return possible_set[ix][0]\n",
    "    \n",
    "for word in ['blus', 'brown', 'reddish', 'yellwo', 'yllow', 'blu']:\n",
    "    print(get_correct_word(word, exp_correct_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
